{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network on Airport reviews data (NN from sklearn). Recommended rating prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries. We are going to use pandas to load data and MLPClassifier from sklearn for NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Natural language toolkit\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from nltk.corpus import stopwords\n",
    "import re as re\n",
    "\n",
    "\n",
    "# Used for stemming words\n",
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data file, droping unused attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reads CVS file as pandas\n",
    "def readDataPandas():\n",
    "    reader = pd.read_csv('Project_Code/data/airlinequality.csv',encoding = 'utf8')\n",
    "\n",
    "    return reader\n",
    "\n",
    "#Removes unused columns\n",
    "def chooseTheAttributes(dataset):\n",
    "\n",
    "    new_data = dataset.drop(['link', 'title','airport_name','author',\n",
    "                             'author_country','overall_rating',\n",
    "                             'queuing_rating','airport_shopping_rating',\n",
    "                             'date','experience_airport',\n",
    "                             'date_visit','type_traveller',\n",
    "                             'terminal_cleanliness_rating',\n",
    "                             'terminal_seating_rating',\n",
    "                             'terminal_signs_rating',\n",
    "                             'food_beverages_rating',\n",
    "                             'wifi_connectivity_rating',\n",
    "                             'airport_staff_rating'], axis=1)\n",
    "\n",
    "    return new_data\n",
    "\n",
    "dataset = readDataPandas()\n",
    "dataset= chooseTheAttributes(dataset)\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Total length of the dataset: <b>17721</b>\n",
    "<li>Training dataset length: <b>12721</b>\n",
    "<li>Test dataset length: <b>5000</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length 12721\n",
      "Test dataset length 5000\n"
     ]
    }
   ],
   "source": [
    "new_train_dataset = dataset[0:12721]\n",
    "testing_results_dataset = dataset[12721:]\n",
    "\n",
    "print(\"Train dataset length %s\" % len(new_train_dataset))\n",
    "print(\"Test dataset length %s\" % len(testing_results_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reviewsToWords(review):\n",
    "\n",
    "\n",
    "\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\",  # The pattern to search for\n",
    "                          \" \",  # The pattern to replace it with\n",
    "                          review)  # The text to search\n",
    "\n",
    "    lower_case = letters_only.lower() #Converts to lower case\n",
    "    words = lower_case.split()  #Splits into seperate words\n",
    "\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "    wordsOfReview = [w for w in words if not w in stops] #Removes un-useful words (stops)\n",
    "\n",
    "    returnValue = ( \" \".join(wordsOfReview))   #Joins together words with space\n",
    "\n",
    "\n",
    "    return returnValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing CountVectorizer which takes the data and transforms it to vectorized array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2814 positive and 9907 negative values\n",
      "The percentage - 22.1209024448 positive, 77.8790975552 negative\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1)\n",
    "\n",
    "count_positive=0\n",
    "count_negative=0\n",
    "training_dataset=[]\n",
    "for index, row in new_train_dataset.iterrows():\n",
    "        training_dataset.append(reviewsToWords(row['content']))\n",
    "        if(row['recommended'] == 1):\n",
    "            count_positive+=1\n",
    "        else:\n",
    "            count_negative+=1\n",
    "  \n",
    "#Fits all the data\n",
    "X = vectorizer.fit_transform(training_dataset)\n",
    "\n",
    "print(\"There are %s positive and %s negative values\" % (count_positive,count_negative))\n",
    "print(\"The percentage - %s positive, %s negative\" % ((count_positive/float(count_positive+count_negative))*100,\n",
    "                                                     (count_negative/float(count_positive+count_negative))*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking one review by one and transforming it to vectorized array compared to the whole dataset.\n",
    "<li> Example: </li>\n",
    "full = [\"Mary likes dogs\"] <br/>\n",
    "train = [\"I like cats\"] <br/>\n",
    "output = [0 1 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our training data\n",
    "training = []\n",
    "output = []\n",
    "\n",
    "# Create an empty array for our output\n",
    "output_empty = [0] * 2\n",
    "\n",
    "for index, row in new_train_dataset.iterrows():\n",
    "    bag=[]\n",
    "    \n",
    "    bag.append(vectorizer.transform([row['content']]).toarray())\n",
    "    \n",
    "    training.append(bag[0][0])\n",
    "\n",
    "    if (row['recommended'] == 1):\n",
    "        output.append([1,0])\n",
    "    else:\n",
    "        output.append([0,1])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating classifier.<br/>\n",
    "<b>learning_rate </b> = adaptive <br/>\n",
    "<b>for activation function we use </b> = the hyperbolic tan function <br/>\n",
    "<b>solver </b> = 'adam' (works best for large datasets) <br />\n",
    "<b>hidden layer size </b> = 1 layer, 8 neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(max_iter=100,\n",
    "                    learning_rate='adaptive',\n",
    "                    activation='logistic',\n",
    "                    solver='lbfgs', \n",
    "                    alpha=1e-5,\n",
    "                    hidden_layer_sizes=(8, 1), \n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit training and output lists. <i>(Takes a long time)</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(8, 1), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array(training)\n",
    "y = np.array(output)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall evaluation, %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: \n",
      "71.68\n",
      "True positive percentage 66.4556962025\n",
      "True negative percentage 73.1638418079\n",
      "False positive percentage 33.5443037975\n",
      "False negative percentage 26.8361581921\n"
     ]
    }
   ],
   "source": [
    "#Accuracy counter and total counter\n",
    "acc_counter = 0\n",
    "total = len(testing_results_dataset)\n",
    "one_counter=0\n",
    "total_ones = 0\n",
    "zero_counter = 0\n",
    "total_zeros =0\n",
    "\n",
    "#Goes throught test data, compares the results with classify\n",
    "for index, row in testing_results_dataset.iterrows():\n",
    "    result = vectorizer.transform([reviewsToWords(row['content'])]).toarray()\n",
    "    result = clf.predict(result)\n",
    "    if(result[0][0] == row['recommended']):\n",
    "        acc_counter+=1\n",
    "        \n",
    "    #Testing if the algorithm is not just guessing 0 and getting high accuracy        \n",
    "    if(row['recommended'] == 1):\n",
    "        total_ones+=1\n",
    "    if(row['recommended'] == 0):\n",
    "        total_zeros+=1\n",
    "    if(result[0][0] == row['recommended'] and row['recommended'] == 1):\n",
    "         one_counter+=1  \n",
    "    if(result[0][0] == row['recommended'] and row['recommended'] == 0):\n",
    "         zero_counter+=1  \n",
    "        \n",
    "print(\"Total accuracy: \")\n",
    "print(acc_counter/float(total) * 100)  \n",
    "print(\"True positive percentage %s\" % (one_counter/float(total_ones) * 100))\n",
    "print(\"True negative percentage %s\" % (zero_counter/float(total_zeros) * 100))\n",
    "print(\"False positive percentage %s\" % (100 - (one_counter/float(total_ones) * 100)))\n",
    "print(\"False negative percentage %s\" % (100 - (zero_counter/float(total_zeros) * 100)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
